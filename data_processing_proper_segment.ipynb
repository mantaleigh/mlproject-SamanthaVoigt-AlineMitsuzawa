{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import sparse\n",
    "import scipy.sparse as sp\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "airbnb_files = ['data/raw_data/Austin_listings.csv', 'data/raw_data/Boston_listings.csv', 'data/raw_data/Asheville_listings.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def drop_airbnb_cols(filename):\n",
    "    '''\n",
    "        input: a filename for detailed airbnb listing data\n",
    "        output: a pandas dataframe with unecessary columns dropped\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    df.drop(['id', 'listing_url', 'scrape_id', 'last_scraped', 'thumbnail_url', 'medium_url', 'picture_url', \\\n",
    "             'xl_picture_url', 'host_id', 'host_url', 'host_thumbnail_url', 'host_picture_url', 'calendar_last_scraped', \\\n",
    "             'weekly_price', 'monthly_price', 'neighbourhood_cleansed', 'license', 'jurisdiction_names', 'square_feet', \\\n",
    "             'neighbourhood', 'calculated_host_listings_count', 'first_review', 'last_review', 'country', 'country_code', \\\n",
    "            'latitude', 'longitude', 'host_name', 'host_location', 'market', 'state', 'city', 'is_location_exact', \\\n",
    "            'smart_location', 'has_availability', 'calendar_updated', 'host_listings_count', 'experiences_offered', \\\n",
    "            'host_since'], axis=1, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_col_names(files):\n",
    "    '''\n",
    "        input: a list of detailed airbnb listing data files\n",
    "        output: a list of common column names (columns that occur in all the files)\n",
    "    '''\n",
    "    \n",
    "    counts = {}\n",
    "    \n",
    "    for f in files: \n",
    "        for c in drop_airbnb_cols(f).columns: \n",
    "            if c in counts: \n",
    "                counts[c] += 1\n",
    "            else: \n",
    "                counts[c] = 1\n",
    "\n",
    "    cols = []\n",
    "    for c in counts: \n",
    "        if counts[c] == len(files):\n",
    "            cols.append(c)\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_price_col(df): \n",
    "    '''\n",
    "        Clean the price column (get rid of symbols and turn it into a float).\n",
    "        Returns the modified dataframe. \n",
    "    '''\n",
    "    \n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df['price'] = df['price'].apply(pd.to_numeric) # turn the price col into a number col\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def segment(X, y): \n",
    "    '''\n",
    "        Separates an X vector and corresponding y vector into train and test data in an 85%/15% division.\n",
    "    \n",
    "        input: \n",
    "            - a vector of featurized data\n",
    "            - a list of existing featurized training data\n",
    "            - a list of existing featurized development data\n",
    "            - a list of existing featurized testing data\n",
    "        \n",
    "        output: \n",
    "            - X_train, X_test, y_train, y_test\n",
    "    '''\n",
    "    if col_type == 'text':\n",
    "        vector = vector.tocsr()\n",
    "        count = vector.shape[0]\n",
    "        if type(train) is sp.csr.csr_matrix: # if values are already defined bc vstack requires same shape\n",
    "            test = sp.vstack([test, vector[-1*int(count*.1):]])\n",
    "            dev = sp.vstack([dev, vector[-1*int(count*.2):-1*int(count*.1)]])\n",
    "            train = sp.vstack([train, vector[:int(count*.8)]])\n",
    "        else:\n",
    "            test = vector[-1*int(count*.1):]\n",
    "            dev = vector[-1*int(count*.2):-1*int(count*.1)]\n",
    "            train = vector[:int(count*.8)]\n",
    "        print col_type, vector.shape\n",
    "    else:\n",
    "        count = len(vector)\n",
    "        test += vector[-1*int(count*.1):]\n",
    "        dev += vector[-1*int(count*.2):-1*int(count*.1)]\n",
    "        train += vector[:int(count*.8)]\n",
    "        print col_type, len(vector)\n",
    "\n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize(df):\n",
    "    '''\n",
    "        old featurize function from milestone 2, will be replaced with individual functions for each col category\n",
    "    '''\n",
    "    \n",
    "#     df = clean_price_col(df)\n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df[['price']] = df[['price']].apply(pd.to_numeric)\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove('price')\n",
    "    cols = ['price'] + cols # put price as the 0th field in the rows\n",
    "    df = df[cols]\n",
    "    \n",
    "    text_cols = df.select_dtypes(exclude=['float64', 'int64']) # get text fields (naïvely)\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']) # get number fields (naïvely)\n",
    "    num_cols.fillna(value=0, inplace=True) # fill all NA number fields with 0\n",
    "    \n",
    "    return [list(i) for i in num_cols.as_matrix()] # turn matrix of num cols into a list of lists to write to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize_categorical(df):\n",
    "#     df = clean_price_col(df)\n",
    "    print 'df len: ', len(df)\n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df[['price']] = df[['price']].apply(pd.to_numeric)\n",
    "    # boolean\n",
    "    bool_cols = ['require_guest_profile_picture', 'require_guest_phone_verification', 'requires_license', 'instant_bookable']\n",
    "    bool_map = {'t': 1, 'f': 0}\n",
    "    for col in bool_cols:\n",
    "        df[col].replace(bool_map, inplace=True)\n",
    "    # categorical - rn treating everything else as categorical to simplify things\n",
    "     # TODO: separate ordinal columns\n",
    "    categorical_cols = ['bed_type', 'cancellation_policy', 'room_type']\n",
    "    for col in categorical_cols:\n",
    "        unique_vals = df[col].unique()\n",
    "        cat_map = { unique_vals[i]: i for i in range(len(unique_vals)) }\n",
    "        df[col].replace(cat_map, inplace=True) # slow but ok for now\n",
    "    v = [list(i) for i in df.as_matrix()]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize_text(df):\n",
    "#     df = clean_price_col(df) # for some reason this fn is breaking my code\n",
    "    print 'text len df: ', len(df)\n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df[['price']] = df[['price']].apply(pd.to_numeric) # turn the price col into a number col\n",
    "    prices = df['price']\n",
    "    X = prices.reshape(prices.shape[0], -1)\n",
    "    for col in df.columns:\n",
    "        if col != 'price':\n",
    "            corpus = df[col].fillna(value=\"\").values #np complains bc i'm modifying a view\n",
    "            vectorizer = CountVectorizer(stop_words='english', max_features=500)\n",
    "            x = vectorizer.fit_transform(corpus) #TODO: clean text\n",
    "            X = sp.hstack((X, x))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_percents(x):\n",
    "    try: \n",
    "        if math.isnan(x): \n",
    "            return x\n",
    "    except TypeError: \n",
    "        return float(x.strip('%'))/100\n",
    "    \n",
    "def clean_prices(x):\n",
    "    try: \n",
    "        if math.isnan(x): \n",
    "            return x\n",
    "    except TypeError: \n",
    "        return float(x.replace('$',\"\").replace(',',\"\"))\n",
    "\n",
    "def featurize_num(df): \n",
    "#     df = clean_price(df)\n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df[['price']] = df[['price']].apply(pd.to_numeric)\n",
    "    # clean up\n",
    "    df['host_response_rate'] = df['host_response_rate'].apply(clean_percents)\n",
    "    df['host_acceptance_rate'] = df['host_acceptance_rate'].apply(clean_percents)\n",
    "    df['security_deposit'] = df['security_deposit'].apply(clean_prices)\n",
    "    df['cleaning_fee'] = df['cleaning_fee'].apply(clean_prices)\n",
    "    df['extra_people'] = df['extra_people'].apply(clean_prices)\n",
    "    \n",
    "    # threshold maximum_nights to 365 if it's over\n",
    "    df.ix[df.maximum_nights > 365, 'maximum_nights'] = 365\n",
    "    \n",
    "    # change nan's to 0 \n",
    "    to_change_to_0 = ['reviews_per_month', 'beds', 'bedrooms', 'bathrooms', 'host_response_rate', 'host_acceptance_rate', \\\n",
    "                     'review_scores_accuracy', 'review_scores_communication', 'review_scores_cleanliness', \\\n",
    "                      'review_scores_location', 'review_scores_rating', 'review_scores_value', 'review_scores_checkin', \n",
    "                     'security_deposit', 'cleaning_fee', 'extra_people']\n",
    "    for col in to_change_to_0: \n",
    "        df[col].fillna(value=0,inplace=True)\n",
    "    \n",
    "    v = [list(i) for i in df.as_matrix()]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def separate_cols(files): \n",
    "    '''\n",
    "        Separates out the different column types into 3 lists of column names. \n",
    "        \n",
    "        input: list of airbnb data files\n",
    "        output: a tuple of length three \n",
    "    '''\n",
    "\n",
    "    cols = get_col_names(files)\n",
    "\n",
    "    label_col = ['price']\n",
    "    # ones that are never null\n",
    "    categorical_cols = ['require_guest_profile_picture', 'require_guest_phone_verification', 'requires_license', \\\n",
    "                        'instant_bookable', 'bed_type', 'cancellation_policy', 'room_type']\n",
    "    num_cols = ['number_of_reviews', 'accommodates', 'minimum_nights', 'maximum_nights', 'guests_included', \\\n",
    "                'availability_30', 'availability_60', 'availability_90', 'availability_365', 'reviews_per_month', \\\n",
    "               'beds', 'bedrooms', 'bathrooms', 'host_response_rate', 'host_acceptance_rate', \\\n",
    "                'review_scores_accuracy', 'review_scores_communication', 'review_scores_cleanliness', \\\n",
    "                'review_scores_location', 'review_scores_rating', 'review_scores_value', 'review_scores_checkin', \\\n",
    "               'security_deposit', 'cleaning_fee', 'extra_people']\n",
    "    \n",
    "    # c nulls to \"\" \n",
    "    text_cols = ['name', 'neighborhood_overview', 'summary', 'transit', 'street', 'host_neighbourhood', 'notes', 'space', 'description']\n",
    "    \n",
    "    return label_col+categorical_cols, label_col+num_cols, label_col+text_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )\n",
    "    \n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return sp.csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])\n",
    "\n",
    "def save_datasets(col_type, vector):\n",
    "    '''\n",
    "        input: \n",
    "            - col_type: categorical, text, num\n",
    "            - featurized vector (not split into text, train)\n",
    "            \n",
    "        Saves 1 file with col_type prefix\n",
    "    '''\n",
    "    if col_type == 'text':\n",
    "        save_sparse_csr('data/' + col_type + '_features.sparse', vector)\n",
    "    else: \n",
    "        with open('data/' + col_type + '_features.csv', 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(vector)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    '''\n",
    "        Creates train, dev, and test files for each column type (categorical, num, text)\n",
    "    '''\n",
    "    \n",
    "    # this could be cleaned up with a loop for modularity\n",
    "    \n",
    "    categorical_cols, num_cols, text_cols = separate_cols(airbnb_files)\n",
    "    all_text_df = pd.DataFrame()\n",
    "    all_num_df = pd.DataFrame()\n",
    "    all_categorical_df = pd.DataFrame()\n",
    "\n",
    "    for f in airbnb_files:   \n",
    "        df = pd.read_csv(f, dtype={'zipcode': 'str'})\n",
    "        \n",
    "        categorical_df = df[categorical_cols]\n",
    "        num_df = df[num_cols]\n",
    "        text_df = df[text_cols]\n",
    "\n",
    "        all_text_df = all_text_df.append(text_df)\n",
    "        all_num_df = all_num_df.append(num_df)\n",
    "        all_categorical_df = all_categorical_df.append(categorical_df)      \n",
    "        \n",
    "    text_vector = featurize_text(all_text_df)\n",
    "#     text_train, text_dev, text_test = segment('text', text_vector, text_train, text_dev, text_test)\n",
    "    \n",
    "    categorical_vector = featurize_categorical(all_categorical_df)\n",
    "#     categorical_train, categorical_dev, categorical_test = segment('categorical', categorical_vector, categorical_train, categorical_dev, categorical_test)\n",
    "    \n",
    "    num_vector = featurize_num(all_num_df)\n",
    "#     num_train, num_dev, num_test = segment('num', num_vector, num_train, num_dev, num_test)\n",
    "        \n",
    "    save_datasets('categorical', categorical_vector)\n",
    "    save_datasets('num', num_vector)\n",
    "    save_datasets('text', text_vector.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text len df:  10284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/ipykernel/__main__.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df len:  10284\n",
      "shit:  10284\n"
     ]
    }
   ],
   "source": [
    "create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def append_column_wise(orig, to_append):\n",
    "    for item,lst in zip(to_append,orig): \n",
    "            lst.insert(0,item)\n",
    "            print lst\n",
    "    return orig\n",
    "\n",
    "def read_files_to_datasets(files): \n",
    "    '''\n",
    "        Returns x_train, y_train, x_test, y_test\n",
    "    '''\n",
    "    \n",
    "    # segment in here\n",
    "    \n",
    "    X = None\n",
    "    y = None\n",
    "    y_added = False\n",
    "    \n",
    "    for f in files:\n",
    "        if '.csv' in f:\n",
    "            to_add = np.loadtxt(open(f, \"rb\"), delimiter=\",\")\n",
    "        else:\n",
    "            to_add = load_sparse_csr(f)\n",
    "        if y_added:\n",
    "            to_add = np.delete(to_add, 0, 1)\n",
    "            X = np.hstack((X, to_add))\n",
    "        else:\n",
    "            if type(to_add) is np.ndarray:\n",
    "                y = to_add[:, [0]]\n",
    "                y = np.asarray(y).reshape(-1)\n",
    "                to_add = np.delete(to_add, 0, 1)\n",
    "            else: \n",
    "                y = to_add[:, [0]].todense()\n",
    "                y = np.asarray(y).reshape(-1)\n",
    "                to_add = np.delete(to_add.toarray(), 0, 1)\n",
    "\n",
    "            X = to_add\n",
    "            y_added = True    \n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.85)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test # <=== with all types of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lin_reg(X_train, Y_train, X_test, Y_test): \n",
    "    # Create linear regression object\n",
    "    regr = LinearRegression()\n",
    "    print \"created a linear regression obj\"\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, Y_train)\n",
    "    \n",
    "    print \"done fitting\"\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    \n",
    "    plt.scatter(Y_test, regr.predict(X_test))\n",
    "    print \"done predicting\"\n",
    "    plt.xlim(0,1000) # take this out eventually\n",
    "    plt.ylim(0,1000) # take this out eventually\n",
    "    plt.xlabel(\"Prices\")\n",
    "    plt.ylabel(\"Predicted Prices\")\n",
    "    plt.title(\"Prices vs. Predicted Prices\")\n",
    "    \n",
    "    # The mean squared error\n",
    "    mean_squared_error = np.mean((regr.predict(X_test) - Y_test) ** 2)\n",
    "    print(\"Mean squared error: %.2f\"\n",
    "          % mean_squared_error)\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print(\"Root mean squared error: %.2f\" % math.sqrt(mean_squared_error))\n",
    "    print('Variance score: %.2f' % regr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = read_files_to_datasets(['data/text_features.sparse.npz', 'data/num_features.csv', 'data/categorical_features.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 400.,  500.,  225., ...,  265.,   99.,  110.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8741, 4210)\n",
      "(8741,)\n",
      "(1543, 4210)\n",
      "(1543,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done fitting\n",
      "('Coefficients: \\n', array([-36.2694289 ,  58.37569203, -39.09677623, ...,   0.80503402,\n",
      "         3.01593318,  -3.78712796]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,8741) and (4210,) not aligned: 8741 (dim 1) != 4210 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-7c7dec6429be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlin_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-ff7a9d70f9d3>\u001b[0m in \u001b[0;36mlin_reg\u001b[0;34m(X_train, Y_train, X_test, Y_test)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Coefficients: \\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"done predicting\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take this out eventually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 253\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,8741) and (4210,) not aligned: 8741 (dim 1) != 4210 (dim 0)"
     ]
    }
   ],
   "source": [
    "lin_reg(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
