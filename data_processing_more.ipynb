{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import sparse\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "airbnb_files = ['data/raw_data/Austin_listings.csv', 'data/raw_data/Boston_listings.csv', 'data/raw_data/Asheville_listings.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def drop_airbnb_cols(filename):\n",
    "    '''\n",
    "        input: a filename for detailed airbnb listing data\n",
    "        output: a pandas dataframe with unecessary columns dropped\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    df.drop(['id', 'listing_url', 'scrape_id', 'last_scraped', 'thumbnail_url', 'medium_url', 'picture_url', \\\n",
    "             'xl_picture_url', 'host_id', 'host_url', 'host_thumbnail_url', 'host_picture_url', 'calendar_last_scraped', \\\n",
    "             'weekly_price', 'monthly_price', 'neighbourhood_cleansed', 'license', 'jurisdiction_names', 'square_feet', \\\n",
    "             'neighbourhood', 'calculated_host_listings_count', 'first_review', 'last_review', 'country', 'country_code', \\\n",
    "            'latitude', 'longitude', 'host_name', 'host_location', 'market', 'state', 'city', 'is_location_exact', \\\n",
    "            'smart_location', 'has_availability', 'calendar_updated', 'host_listings_count', 'experiences_offered', \\\n",
    "            'host_since'], axis=1, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_col_names(files):\n",
    "    '''\n",
    "        input: a list of detailed airbnb listing data files\n",
    "        output: a list of common column names (columns that occur in all the files)\n",
    "    '''\n",
    "    \n",
    "    counts = {}\n",
    "    \n",
    "    for f in files: \n",
    "        for c in drop_airbnb_cols(f).columns: \n",
    "            if c in counts: \n",
    "                counts[c] += 1\n",
    "            else: \n",
    "                counts[c] = 1\n",
    "\n",
    "    cols = []\n",
    "    for c in counts: \n",
    "        if counts[c] == len(files):\n",
    "            cols.append(c)\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_price_col(df): \n",
    "    '''\n",
    "        Clean the price column (get rid of symbols and turn it into a float).\n",
    "        Returns the modified dataframe. \n",
    "    '''\n",
    "    \n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df['price'] = df['price'].apply(pd.to_numeric) # turn the price col into a number col\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def segment(vector, train, dev, test): \n",
    "    '''\n",
    "        Separates a vector into train, dev, and test data in 80%/10%/10% divisions.\n",
    "    \n",
    "        input: \n",
    "            - a vector of featurized data\n",
    "            - a list of existing featurized training data\n",
    "            - a list of existing featurized development data\n",
    "            - a list of existing featurized testing data\n",
    "        \n",
    "        output: \n",
    "            - train, dev, and test lists that include the existing featurized dataset (from the input) \n",
    "                appended with data from the input vector\n",
    "    '''\n",
    "    \n",
    "    count = len(vector)\n",
    "    test += vector[-1*int(count*.1):]\n",
    "    dev += vector[-1*int(count*.2):-1*int(count*.1)]\n",
    "    train += vector[:int(count*.8)]\n",
    "    \n",
    "    return train, dev, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize(df):\n",
    "    '''\n",
    "        old featurize function from milestone 2, will be replaced with individual functions for each col category\n",
    "    '''\n",
    "    \n",
    "    df = clean_price_col(df)\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove('price')\n",
    "    cols = ['price'] + cols # put price as the 0th field in the rows\n",
    "    df = df[cols]\n",
    "    \n",
    "    text_cols = df.select_dtypes(exclude=['float64', 'int64']) # get text fields (naïvely)\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']) # get number fields (naïvely)\n",
    "    num_cols.fillna(value=0, inplace=True) # fill all NA number fields with 0\n",
    "    \n",
    "    return [list(i) for i in num_cols.as_matrix()] # turn matrix of num cols into a list of lists to write to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize_categorical(df):\n",
    "    df = clean_price_col(df)\n",
    "    \n",
    "    # boolean\n",
    "    bool_cols = ['require_guest_profile_picture', 'require_guest_phone_verification', 'requires_license', 'instant_bookable']\n",
    "    bool_map = {'t': 1, 'f': 0}\n",
    "    for col in bool_cols:\n",
    "        df[col].replace(bool_map, inplace=True)\n",
    "    # categorical - rn treating everything else as categorical to simplify things\n",
    "     # TODO: separate ordinal columns\n",
    "    categorical_cols = ['bed_type', 'cancellation_policy', 'room_type']\n",
    "    for col in categorical_cols:\n",
    "        unique_vals = df[col].unique()\n",
    "        cat_map = { unique_vals[i]: i for i in range(len(unique_vals)) }\n",
    "        df[col].replace(cat_map, inplace=True) # slow but ok for now\n",
    "    v = [list(i) for i in df.as_matrix()]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize_text(df):\n",
    "    # TODO: refactor\n",
    "    df = clean_price_col(df)\n",
    "    \n",
    "    prices = df['price'].tolist()\n",
    "    X = [[prices[i]] for i in range(len(prices))]\n",
    "    for col in df.columns:\n",
    "        if col != 'price':\n",
    "            corpus = df[col].fillna(value=\"\").values\n",
    "            vectorizer = CountVectorizer()\n",
    "            x = vectorizer.fit_transform(corpus) #TODO: clean text\n",
    "            for i, bow in enumerate(x):\n",
    "                indices = bow.indices\n",
    "                num = bow.data\n",
    "                data = zip(indices, num)\n",
    "                X[i] += [str(datum[0]) + ':' + str(datum[1]) for datum in data]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_percents(x):\n",
    "    try: \n",
    "        if math.isnan(x): \n",
    "            return x\n",
    "    except TypeError: \n",
    "        return float(x.strip('%'))/100\n",
    "    \n",
    "def clean_prices(x):\n",
    "    try: \n",
    "        if math.isnan(x): \n",
    "            return x\n",
    "    except TypeError: \n",
    "        return float(x.replace('$',\"\").replace(',',\"\"))\n",
    "\n",
    "def featurize_num(df): \n",
    "    df = clean_price(df)\n",
    "\n",
    "    # clean up\n",
    "    df['host_response_rate'] = df['host_response_rate'].apply(clean_percents)\n",
    "    df['host_acceptance_rate'] = df['host_acceptance_rate'].apply(clean_percents)\n",
    "    df['security_deposit'] = df['security_deposit'].apply(clean_prices)\n",
    "    df['cleaning_fee'] = df['cleaning_fee'].apply(clean_prices)\n",
    "    df['extra_people'] = df['extra_people'].apply(clean_prices)\n",
    "    \n",
    "    # threshold maximum_nights to 365 if it's over\n",
    "    df.ix[df.maximum_nights > 365, 'maximum_nights'] = 365\n",
    "    \n",
    "    # change nan's to 0 \n",
    "    to_change_to_0 = ['reviews_per_month', 'beds', 'bedrooms', 'bathrooms', 'host_response_rate', 'host_acceptance_rate', \\\n",
    "                     'review_scores_accuracy', 'review_scores_communication', 'review_scores_cleanliness', \\\n",
    "                      'review_scores_location', 'review_scores_rating', 'review_scores_value', 'review_scores_checkin', \n",
    "                     'security_deposit', 'cleaning_fee', 'extra_people']\n",
    "    for col in to_change_to_0: \n",
    "        df[col].fillna(value=0,inplace=True)\n",
    "    \n",
    "    v = [list(i) for i in df.as_matrix()]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def separate_cols(files): \n",
    "    '''\n",
    "        Separates out the different column types into 3 lists of column names. \n",
    "        \n",
    "        input: list of airbnb data files\n",
    "        output: a tuple of length three \n",
    "    '''\n",
    "\n",
    "    cols = get_col_names(files)\n",
    "\n",
    "    label_col = ['price']\n",
    "    # ones that are never null\n",
    "    categorical_cols = ['require_guest_profile_picture', 'require_guest_phone_verification', 'requires_license', \\\n",
    "                        'instant_bookable', 'bed_type', 'cancellation_policy', 'room_type']\n",
    "    num_cols = ['number_of_reviews', 'accommodates', 'minimum_nights', 'maximum_nights', 'guests_included', \\\n",
    "                'availability_30', 'availability_60', 'availability_90', 'availability_365', 'reviews_per_month', \\\n",
    "               'beds', 'bedrooms', 'bathrooms', 'host_response_rate', 'host_acceptance_rate', \\\n",
    "                'review_scores_accuracy', 'review_scores_communication', 'review_scores_cleanliness', \\\n",
    "                'review_scores_location', 'review_scores_rating', 'review_scores_value', 'review_scores_checkin', \\\n",
    "               'security_deposit', 'cleaning_fee', 'extra_people']\n",
    "    \n",
    "    # c nulls to \"\" \n",
    "    text_cols = ['name', 'neighborhood_overview', 'summary', 'transit', 'street', 'host_neighbourhood', 'notes', 'space', 'description']\n",
    "    \n",
    "    return label_col+categorical_cols, label_col+num_cols, label_col+text_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_datasets(col_type, train, dev, test):\n",
    "    '''\n",
    "        input: \n",
    "            - col_type: categorical, text, num\n",
    "            - train, dev, and test lists of featurized vectors\n",
    "            \n",
    "        Saves 3 csv files: train, dev, and test with col_type prefix\n",
    "    '''\n",
    "    \n",
    "    with open('data/' + col_type + '_train.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(train)\n",
    "\n",
    "    with open('data/' + col_type + '_dev.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(dev)\n",
    "\n",
    "    with open('data/' + col_type + '_test.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(test)\n",
    "        \n",
    "def save_sparse_datasets(col_type, train, dev, test):\n",
    "    train_name = 'data/' + col_type + '_train.csv'\n",
    "    dev_name = 'data/' + col_type + '_dev.csv'\n",
    "    test_name = 'data/' + col_type + '_test.csv'\n",
    "    save_sparse_csr(train_name, train)\n",
    "    save_sparse_csr(dev_name, dev)\n",
    "    save_sparse_csr(test_name, test)\n",
    "    \n",
    "def save_sparse_csr(filename,array):\n",
    "    array = sparse.csr_matrix(array)\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )\n",
    "    \n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    '''\n",
    "        Creates train, dev, and test files for each column type (categorical, num, text)\n",
    "    '''\n",
    "    \n",
    "    # this could be cleaned up with a loop for modularity\n",
    "    \n",
    "    categorical_train = []\n",
    "    num_train = []\n",
    "    text_train = []\n",
    "    \n",
    "    categorical_dev = []\n",
    "    num_dev = []\n",
    "    text_dev = []\n",
    "    \n",
    "    categorical_test = []\n",
    "    num_test = []\n",
    "    text_test = []\n",
    "    \n",
    "    categorical_cols, num_cols, text_cols = separate_cols(airbnb_files)\n",
    "\n",
    "    for f in airbnb_files:   \n",
    "        df = pd.read_csv(f, dtype={'zipcode': 'str'})\n",
    "        \n",
    "        categorical_df = df[categorical_cols]\n",
    "        num_df = df[num_cols]\n",
    "        text_df = df[text_cols]\n",
    "        \n",
    "        categorical_vector = featurize_categorical(categorical_df)\n",
    "        num_vector = featurize_num(num_df)\n",
    "#         text_vector = featurize_text(text_df)\n",
    "\n",
    "        categorical_train, categorical_dev, categorical_test = segment(categorical_vector, categorical_train, categorical_dev, categorical_test)\n",
    "        num_train, num_dev, num_test = segment(num_vector, num_train, num_dev, num_test)\n",
    "#         text_train, text_dev, text_test = segment(text_vector, text_train, text_dev, text_test)\n",
    "        \n",
    "    save_datasets('categorical', categorical_train, categorical_dev, categorical_test)\n",
    "    save_datasets('num', num_train, num_dev, num_test)\n",
    "#     save_datasets('text', text_train, text_dev, text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/samanthavoigt/Documents/Wellesley/ML/venv/lib/python2.7/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def append_column_wise(orig, to_append):\n",
    "    for item,lst in zip(to_append,orig): \n",
    "            lst.insert(0,item)\n",
    "            print lst\n",
    "    return orig\n",
    "\n",
    "def read_files_to_datasets(train_files, test_files): \n",
    "    '''\n",
    "        Returns x_train, y_train, x_test, y_test\n",
    "    '''\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for f in train_files:\n",
    "        train_df = pd.read_csv(f)\n",
    "  \n",
    "        y_train_to_add = train_df[train_df.columns[0]].values.tolist()\n",
    "        x_train_to_add = train_df[train_df.columns[1:]].values.tolist()\n",
    "\n",
    "        x_train = append_column_wise(x_train, x_train_to_add)\n",
    "        y_train = append_column_wise(y_train, y_train_to_add)\n",
    "        \n",
    "        print y_train\n",
    "        print x_train\n",
    "    \n",
    "    for f in test_files:\n",
    "        test_df = pd.read_csv(f)\n",
    "    \n",
    "    \n",
    "\n",
    "#     y_train = train_df[train_df.columns[0]].as_matrix()\n",
    "#     \n",
    "#     y_test = test_df[test_df.columns[0]].as_matrix()\n",
    "#     x_test = test_df[test_df.columns[1:]].as_matrix()\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lin_reg(X_train, Y_train, X_test, Y_test): \n",
    "    # Create linear regression object\n",
    "    regr = LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, Y_train)\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    # The mean squared error\n",
    "    mean_squared_error = np.mean((regr.predict(X_test) - Y_test) ** 2)\n",
    "    print(\"Mean squared error: %.2f\"\n",
    "          % mean_squared_error)\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print(\"Root mean squared error: %.2f\" % math.sqrt(mean_squared_error))\n",
    "    print('Variance score: %.2f' % regr.score(X_test, Y_test))\n",
    "    \n",
    "    plt.scatter(Y_test, regr.predict(X_test))\n",
    "    plt.xlim(0,200) # take this out eventually\n",
    "    plt.ylim(0,200) # take this out eventually\n",
    "    plt.xlabel(\"Prices\")\n",
    "    plt.ylabel(\"Predicted Prices\")\n",
    "    plt.title(\"Prices vs. Predicted Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# create_datasets()\n",
    "x_train, y_train, x_test, y_test = read_files_to_datasets(['data/num_train.csv', 'data/categorical_train.csv'], ['data/num_test.csv', 'data/categorical_test.csv'])\n",
    "# lin_reg(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
