{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import sparse\n",
    "import scipy.sparse as sp\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "airbnb_files = ['data/raw_data/Austin_listings.csv', 'data/raw_data/Boston_listings.csv', 'data/raw_data/Asheville_listings.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def drop_airbnb_cols(filename):\n",
    "    '''\n",
    "        input: a filename for detailed airbnb listing data\n",
    "        output: a pandas dataframe with unecessary columns dropped\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    df.drop(['id', 'listing_url', 'scrape_id', 'last_scraped', 'thumbnail_url', 'medium_url', 'picture_url', \\\n",
    "             'xl_picture_url', 'host_id', 'host_url', 'host_thumbnail_url', 'host_picture_url', 'calendar_last_scraped', \\\n",
    "             'weekly_price', 'monthly_price', 'neighbourhood_cleansed', 'license', 'jurisdiction_names', 'square_feet', \\\n",
    "             'neighbourhood', 'calculated_host_listings_count', 'first_review', 'last_review', 'country', 'country_code', \\\n",
    "            'latitude', 'longitude', 'host_name', 'host_location', 'market', 'state', 'city', 'is_location_exact', \\\n",
    "            'smart_location', 'has_availability', 'calendar_updated', 'host_listings_count', 'experiences_offered', \\\n",
    "            'host_since'], axis=1, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_col_names(files):\n",
    "    '''\n",
    "        input: a list of detailed airbnb listing data files\n",
    "        output: a list of common column names (columns that occur in all the files)\n",
    "    '''\n",
    "    \n",
    "    counts = {}\n",
    "    \n",
    "    for f in files: \n",
    "        for c in drop_airbnb_cols(f).columns: \n",
    "            if c in counts: \n",
    "                counts[c] += 1\n",
    "            else: \n",
    "                counts[c] = 1\n",
    "\n",
    "    cols = []\n",
    "    for c in counts: \n",
    "        if counts[c] == len(files):\n",
    "            cols.append(c)\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_price_col(df): \n",
    "    '''\n",
    "        Clean the price column (get rid of symbols and turn it into a float).\n",
    "        Returns the modified dataframe. \n",
    "    '''\n",
    "    \n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df['price'] = df['price'].apply(pd.to_numeric) # turn the price col into a number col\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def segment(col_type, vector, train, dev, test): \n",
    "    '''\n",
    "        Separates a vector into train, dev, and test data in 80%/10%/10% divisions.\n",
    "    \n",
    "        input: \n",
    "            - a vector of featurized data\n",
    "            - a list of existing featurized training data\n",
    "            - a list of existing featurized development data\n",
    "            - a list of existing featurized testing data\n",
    "        \n",
    "        output: \n",
    "            - train, dev, and test lists that include the existing featurized dataset (from the input) \n",
    "                appended with data from the input vector\n",
    "    '''\n",
    "    if col_type == 'text':\n",
    "        vector = vector.tocsr()\n",
    "        count = vector.shape[0]\n",
    "        if type(train) is sp.csr.csr_matrix: # if values are already defined bc vstack requires same shape\n",
    "            test = sp.vstack([test, vector[-1*int(count*.1):]])\n",
    "            dev = sp.vstack([dev, vector[-1*int(count*.2):-1*int(count*.1)]])\n",
    "            train = sp.vstack([train, vector[:int(count*.8)]])\n",
    "        else:\n",
    "            test = vector[-1*int(count*.1):]\n",
    "            dev = vector[-1*int(count*.2):-1*int(count*.1)]\n",
    "            train = vector[:int(count*.8)]\n",
    "        print col_type, vector.shape\n",
    "    else:\n",
    "        count = len(vector)\n",
    "        test += vector[-1*int(count*.1):]\n",
    "        dev += vector[-1*int(count*.2):-1*int(count*.1)]\n",
    "        train += vector[:int(count*.8)]\n",
    "        print col_type, len(vector)\n",
    "\n",
    "    return train, dev, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize(df):\n",
    "    '''\n",
    "        old featurize function from milestone 2, will be replaced with individual functions for each col category\n",
    "    '''\n",
    "    \n",
    "#     df = clean_price_col(df)\n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df[['price']] = df[['price']].apply(pd.to_numeric)\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove('price')\n",
    "    cols = ['price'] + cols # put price as the 0th field in the rows\n",
    "    df = df[cols]\n",
    "    \n",
    "    text_cols = df.select_dtypes(exclude=['float64', 'int64']) # get text fields (naïvely)\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']) # get number fields (naïvely)\n",
    "    num_cols.fillna(value=0, inplace=True) # fill all NA number fields with 0\n",
    "    \n",
    "    return [list(i) for i in num_cols.as_matrix()] # turn matrix of num cols into a list of lists to write to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize_categorical(df):\n",
    "#     df = clean_price_col(df)\n",
    "    print 'df len: ', len(df)\n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df[['price']] = df[['price']].apply(pd.to_numeric)\n",
    "    # boolean\n",
    "    bool_cols = ['require_guest_profile_picture', 'require_guest_phone_verification', 'requires_license', 'instant_bookable']\n",
    "    bool_map = {'t': 1, 'f': 0}\n",
    "    for col in bool_cols:\n",
    "        df[col].replace(bool_map, inplace=True)\n",
    "    # categorical - rn treating everything else as categorical to simplify things\n",
    "     # TODO: separate ordinal columns\n",
    "    categorical_cols = ['bed_type', 'cancellation_policy', 'room_type']\n",
    "    for col in categorical_cols:\n",
    "        unique_vals = df[col].unique()\n",
    "        cat_map = { unique_vals[i]: i for i in range(len(unique_vals)) }\n",
    "        df[col].replace(cat_map, inplace=True) # slow but ok for now\n",
    "    v = [list(i) for i in df.as_matrix()]\n",
    "    print 'shit: ', len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def featurize_text(df):\n",
    "#     df = clean_price_col(df) # for some reason this fn is breaking my code\n",
    "    print 'text len df: ', len(df)\n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df[['price']] = df[['price']].apply(pd.to_numeric) # turn the price col into a number col\n",
    "    prices = df['price']\n",
    "    X = prices.reshape(prices.shape[0], -1)\n",
    "    for col in df.columns:\n",
    "        if col != 'price':\n",
    "            corpus = df[col].fillna(value=\"\").values #np complains bc i'm modifying a view\n",
    "            vectorizer = CountVectorizer(stop_words='english', max_features=500)\n",
    "            x = vectorizer.fit_transform(corpus) #TODO: clean text\n",
    "            X = sp.hstack((X, x))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_percents(x):\n",
    "    try: \n",
    "        if math.isnan(x): \n",
    "            return x\n",
    "    except TypeError: \n",
    "        return float(x.strip('%'))/100\n",
    "    \n",
    "def clean_prices(x):\n",
    "    try: \n",
    "        if math.isnan(x): \n",
    "            return x\n",
    "    except TypeError: \n",
    "        return float(x.replace('$',\"\").replace(',',\"\"))\n",
    "\n",
    "def featurize_num(df): \n",
    "#     df = clean_price(df)\n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df[['price']] = df[['price']].apply(pd.to_numeric)\n",
    "    # clean up\n",
    "    df['host_response_rate'] = df['host_response_rate'].apply(clean_percents)\n",
    "    df['host_acceptance_rate'] = df['host_acceptance_rate'].apply(clean_percents)\n",
    "    df['security_deposit'] = df['security_deposit'].apply(clean_prices)\n",
    "    df['cleaning_fee'] = df['cleaning_fee'].apply(clean_prices)\n",
    "    df['extra_people'] = df['extra_people'].apply(clean_prices)\n",
    "    \n",
    "    # threshold maximum_nights to 365 if it's over\n",
    "    df.ix[df.maximum_nights > 365, 'maximum_nights'] = 365\n",
    "    \n",
    "    # change nan's to 0 \n",
    "    to_change_to_0 = ['reviews_per_month', 'beds', 'bedrooms', 'bathrooms', 'host_response_rate', 'host_acceptance_rate', \\\n",
    "                     'review_scores_accuracy', 'review_scores_communication', 'review_scores_cleanliness', \\\n",
    "                      'review_scores_location', 'review_scores_rating', 'review_scores_value', 'review_scores_checkin', \n",
    "                     'security_deposit', 'cleaning_fee', 'extra_people']\n",
    "    for col in to_change_to_0: \n",
    "        df[col].fillna(value=0,inplace=True)\n",
    "    \n",
    "    v = [list(i) for i in df.as_matrix()]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def separate_cols(files): \n",
    "    '''\n",
    "        Separates out the different column types into 3 lists of column names. \n",
    "        \n",
    "        input: list of airbnb data files\n",
    "        output: a tuple of length three \n",
    "    '''\n",
    "\n",
    "    cols = get_col_names(files)\n",
    "\n",
    "    label_col = ['price']\n",
    "    # ones that are never null\n",
    "    categorical_cols = ['require_guest_profile_picture', 'require_guest_phone_verification', 'requires_license', \\\n",
    "                        'instant_bookable', 'bed_type', 'cancellation_policy', 'room_type']\n",
    "    num_cols = ['number_of_reviews', 'accommodates', 'minimum_nights', 'maximum_nights', 'guests_included', \\\n",
    "                'availability_30', 'availability_60', 'availability_90', 'availability_365', 'reviews_per_month', \\\n",
    "               'beds', 'bedrooms', 'bathrooms', 'host_response_rate', 'host_acceptance_rate', \\\n",
    "                'review_scores_accuracy', 'review_scores_communication', 'review_scores_cleanliness', \\\n",
    "                'review_scores_location', 'review_scores_rating', 'review_scores_value', 'review_scores_checkin', \\\n",
    "               'security_deposit', 'cleaning_fee', 'extra_people']\n",
    "    \n",
    "    # c nulls to \"\" \n",
    "    text_cols = ['name', 'neighborhood_overview', 'summary', 'transit', 'street', 'host_neighbourhood', 'notes', 'space', 'description']\n",
    "    \n",
    "    return label_col+categorical_cols, label_col+num_cols, label_col+text_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )\n",
    "    \n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return sp.csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])\n",
    "\n",
    "def save_sparse_datasets(col_type, train, dev, test):\n",
    "    train_name = 'data/' + col_type + '_train.sparse'\n",
    "    dev_name = 'data/' + col_type + '_dev.sparse'\n",
    "    test_name = 'data/' + col_type + '_test.sparse'\n",
    "    save_sparse_csr(train_name, train)\n",
    "    save_sparse_csr(dev_name, dev)\n",
    "    save_sparse_csr(test_name, test)\n",
    "\n",
    "def save_datasets(col_type, train, dev, test):\n",
    "    '''\n",
    "        input: \n",
    "            - col_type: categorical, text, num\n",
    "            - train, dev, and test lists of featurized vectors\n",
    "            \n",
    "        Saves 3 csv files: train, dev, and test with col_type prefix\n",
    "    '''\n",
    "    if col_type == 'text':\n",
    "        save_sparse_datasets(col_type, train, dev, test)\n",
    "    else: \n",
    "        with open('data/' + col_type + '_train.csv', 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(train)\n",
    "\n",
    "        with open('data/' + col_type + '_dev.csv', 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(dev)\n",
    "\n",
    "        with open('data/' + col_type + '_test.csv', 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    '''\n",
    "        Creates train, dev, and test files for each column type (categorical, num, text)\n",
    "    '''\n",
    "    \n",
    "    # this could be cleaned up with a loop for modularity\n",
    "    \n",
    "    categorical_train = []\n",
    "    num_train = []\n",
    "    text_train = None\n",
    "    \n",
    "    categorical_dev = []\n",
    "    num_dev = []\n",
    "    text_dev = None\n",
    "    \n",
    "    categorical_test = []\n",
    "    num_test = []\n",
    "    text_test = None\n",
    "    \n",
    "    categorical_cols, num_cols, text_cols = separate_cols(airbnb_files)\n",
    "    all_text_df = pd.DataFrame()\n",
    "    all_num_df = pd.DataFrame()\n",
    "    all_categorical_df = pd.DataFrame()\n",
    "\n",
    "    for f in airbnb_files:   \n",
    "        df = pd.read_csv(f, dtype={'zipcode': 'str'})\n",
    "        \n",
    "        categorical_df = df[categorical_cols]\n",
    "        num_df = df[num_cols]\n",
    "        text_df = df[text_cols]\n",
    "\n",
    "        all_text_df = all_text_df.append(text_df)\n",
    "        all_num_df = all_num_df.append(num_df)\n",
    "        all_categorical_df = all_categorical_df.append(categorical_df)      \n",
    "        \n",
    "    text_vector = featurize_text(all_text_df)\n",
    "    text_train, text_dev, text_test = segment('text', text_vector, text_train, text_dev, text_test)\n",
    "    \n",
    "    categorical_vector = featurize_categorical(all_categorical_df)\n",
    "    categorical_train, categorical_dev, categorical_test = segment('categorical', categorical_vector, categorical_train, categorical_dev, categorical_test)\n",
    "    \n",
    "    num_vector = featurize_num(all_num_df)\n",
    "    num_train, num_dev, num_test = segment('num', num_vector, num_train, num_dev, num_test)\n",
    "        \n",
    "    save_datasets('categorical', categorical_train, categorical_dev, categorical_test)\n",
    "    save_datasets('num', num_train, num_dev, num_test)\n",
    "    save_datasets('text', text_train, text_dev, text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text len df:  10284\n",
      "text (10284, 4179)\n",
      "df len:  10284\n",
      "shit:  10284\n",
      "categorical 10284\n",
      "num 10284\n"
     ]
    }
   ],
   "source": [
    "create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def append_column_wise(orig, to_append):\n",
    "    for item,lst in zip(to_append,orig): \n",
    "            lst.insert(0,item)\n",
    "            print lst\n",
    "    return orig\n",
    "\n",
    "def read_files_to_datasets(train_files, test_files): \n",
    "    '''\n",
    "        Returns x_train, y_train, x_test, y_test\n",
    "    '''\n",
    "    \n",
    "    x_train = None\n",
    "    y_train = None\n",
    "    x_test = np.array([])\n",
    "    y_test = None\n",
    "    y_added = False\n",
    "    \n",
    "    for f in train_files:\n",
    "        if '.csv' in f:\n",
    "            to_add = np.loadtxt(open(f, \"rb\"), delimiter=\",\")\n",
    "        else:\n",
    "            to_add = load_sparse_csr(f)\n",
    "        if not y_added:\n",
    "            x_train = to_add\n",
    "            y_train = to_add[:, [0]].todense()\n",
    "            y_added = True\n",
    "        else:\n",
    "            print x_train.shape, to_add.shape\n",
    "            x_train = sp.hstack((x_train, to_add))\n",
    "        to_add = np.delete(to_add, 0, 1)\n",
    "            \n",
    "    y_added = False\n",
    "    \n",
    "    for f in test_files:\n",
    "        if '.csv' in f:\n",
    "            to_add = np.loadtxt(open(f, \"rb\"), delimiter=\",\")\n",
    "        else:\n",
    "            to_add = load_sparse_csr(f)\n",
    "        if not y_added:\n",
    "            x_test = to_add\n",
    "            y_test = to_add[:, [0]].todense()\n",
    "            y_added = True\n",
    "        else:\n",
    "            print x_test.shape, to_add.shape\n",
    "            x_test = sp.hstack((x_test, to_add))\n",
    "        to_add = np.delete(to_add, 0, 1)\n",
    "\n",
    "    x_train = x_train.todense()\n",
    "    x_test = x_test.todense()\n",
    "    \n",
    "    print 'x_train: ', x_train.shape\n",
    "    print 'y_train: ', len(y_train)\n",
    "    print 'x_test: ', x_test.shape\n",
    "    print 'y_test: ', len(y_test)\n",
    "\n",
    "    \n",
    "#         train_df = pd.read_csv(f)\n",
    "  \n",
    "#         y_train_to_add = train_df[train_df.columns[0]].values.tolist()\n",
    "#         x_train_to_add = train_df[train_df.columns[1:]].values.tolist()\n",
    "\n",
    "#         x_train = append_column_wise(x_train, x_train_to_add)\n",
    "#         y_train = append_column_wise(y_train, y_train_to_add)\n",
    "    \n",
    "#     for f in test_files:\n",
    "#         test_df = pd.read_csv(f)\n",
    "    \n",
    "    \n",
    "\n",
    "#     y_train = train_df[train_df.columns[0]].as_matrix()\n",
    "#     \n",
    "#     y_test = test_df[test_df.columns[0]].as_matrix()\n",
    "#     x_test = test_df[test_df.columns[1:]].as_matrix()\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lin_reg(X_train, Y_train, X_test, Y_test): \n",
    "    # Create linear regression object\n",
    "    regr = LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, Y_train)\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    # The mean squared error\n",
    "    mean_squared_error = np.mean((regr.predict(X_test) - Y_test) ** 2)\n",
    "    print(\"Mean squared error: %.2f\"\n",
    "          % mean_squared_error)\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print(\"Root mean squared error: %.2f\" % math.sqrt(mean_squared_error))\n",
    "    print('Variance score: %.2f' % regr.score(X_test, Y_test))\n",
    "    \n",
    "    plt.scatter(Y_test, regr.predict(X_test))\n",
    "    plt.xlim(0,200) # take this out eventually\n",
    "    plt.ylim(0,200) # take this out eventually\n",
    "    plt.xlabel(\"Prices\")\n",
    "    plt.ylabel(\"Predicted Prices\")\n",
    "    plt.title(\"Prices vs. Predicted Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create_datasets()\n",
    "# x_train, y_train, x_test, y_test = read_files_to_datasets(['data/num_train.csv', 'data/categorical_train.csv', 'data/text_train.sparse.npz'], ['data/num_test.csv', 'data/categorical_test.csv', 'data/text_test.sparse.npz'])\n",
    "# lin_reg(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8227, 4179) (8227, 26)\n",
      "(8227, 4205) (8227, 8)\n",
      "(1028, 4179) (1028, 26)\n",
      "(1028, 4205) (1028, 8)\n",
      "x_train:  (8227, 4213)\n",
      "y_train:  8227\n",
      "x_test:  (1028, 4213)\n",
      "y_test:  1028\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = read_files_to_datasets(['data/text_train.sparse.npz', 'data/num_train.csv', 'data/categorical_train.csv'], ['data/text_test.sparse.npz','data/num_test.csv', 'data/categorical_test.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([[  1.32407187e-03,   3.63753913e-13,   4.56909917e-14, ...,\n",
      "          4.61063750e-16,  -6.52418657e-17,  -2.37386066e-16]]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "input must be a square array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7c7dec6429be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlin_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-ca4d7982293d>\u001b[0m in \u001b[0;36mlin_reg\u001b[0;34m(X_train, Y_train, X_test, Y_test)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Coefficients: \\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# The mean squared error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmean_squared_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     print(\"Mean squared error: %.2f\"\n\u001b[1;32m     13\u001b[0m           % mean_squared_error)\n",
      "\u001b[0;32m/Users/amitsuzawa/anaconda/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.pyc\u001b[0m in \u001b[0;36m__pow__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pow__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix_power\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ipow__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amitsuzawa/anaconda/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.pyc\u001b[0m in \u001b[0;36mmatrix_power\u001b[0;34m(M, n)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input must be a square array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exponent must be an integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: input must be a square array"
     ]
    }
   ],
   "source": [
    "lin_reg(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
