{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "airbnb_files = ['data/raw_data/Austin_listings.csv', 'data/raw_data/Boston_listings.csv', 'data/raw_data/Asheville_listings.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def drop_airbnb_cols(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df.drop(['id', 'listing_url', 'scrape_id', 'last_scraped', 'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url', 'host_id', 'host_url', 'host_thumbnail_url', 'host_picture_url', 'calendar_last_scraped', 'weekly_price', 'monthly_price', 'neighbourhood_cleansed', \\\n",
    "             'license', 'jurisdiction_names', 'square_feet', 'neighbourhood', 'calculated_host_listings_count'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_col_names(files):\n",
    "    counts = {}\n",
    "    \n",
    "    for f in files: \n",
    "        for c in drop_airbnb_cols(f).columns: \n",
    "            if c in counts: \n",
    "                counts[c] += 1\n",
    "            else: \n",
    "                counts[c] = 1\n",
    "\n",
    "    cols = []\n",
    "    for c in counts: \n",
    "        if counts[c] == 3:\n",
    "            cols.append(c)\n",
    "    \n",
    "    return cols\n",
    "\n",
    "def segment(vector, train, dev, test): \n",
    "    count = len(vector)\n",
    "    test += vector[-1*int(count*.1):]\n",
    "    dev += vector[-1*int(count*.2):-1*int(count*.1)]\n",
    "    train += vector[:int(count*.8)]\n",
    "    \n",
    "    return train, dev, test\n",
    "    \n",
    "def featurize(df):\n",
    "    \n",
    "    df['price'] = df['price'].map(lambda x: x.replace('$', \"\").replace(',',\"\"))\n",
    "    df[['price']] = df[['price']].apply(pd.to_numeric) # turn the price col into a number col\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove('price')\n",
    "    cols = ['price'] + cols\n",
    "    df = df[cols]\n",
    "    text_cols = df.select_dtypes(exclude=['float64', 'int64'])\n",
    "#     for col in text_cols: \n",
    "#         corpus = df[col].fillna(value=\"\").values\n",
    "#         print corpus\n",
    "#         vectorizer = CountVectorizer()\n",
    "#         X = vectorizer.fit_transform(corpus)\n",
    "#         print X\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64'])\n",
    "    num_cols.fillna(value=0, inplace=True)\n",
    "    return [list(i) for i in num_cols.as_matrix()]\n",
    "    \n",
    "    # call dictvectorizor on that list --> numpy array of features\n",
    "    # convert rest of df into numpy array with price as first value\n",
    "    # append 2 numpy arrays by index\n",
    "    \n",
    "    # return big numpy array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    col_names = get_col_names(airbnb_files)\n",
    "\n",
    "    train = []\n",
    "    dev = []\n",
    "    test = []\n",
    "    \n",
    "    for f in airbnb_files:   \n",
    "        df = pd.read_csv(f, dtype={'zipcode': 'str'})\n",
    "        df = df[col_names]\n",
    "        vector = featurize(df)\n",
    "        train, dev, test = segment(vector, train, dev, test) # put data from f into train, dev, test\n",
    "        \n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_datasets(train, dev, test):\n",
    "    with open('data/train.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(train)\n",
    "\n",
    "    with open('data/dev.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(dev)\n",
    "\n",
    "    with open('data/test.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_datasets(*create_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
